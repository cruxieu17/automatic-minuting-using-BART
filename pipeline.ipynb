{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "basic_arch_bart.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxJAyq85q0dt"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMqu743HrOZr"
      },
      "source": [
        "! pip install datasets transformers rouge-score nltk py7zr\n",
        "import torch\n",
        "torch.cuda.manual_seed(0)\n",
        "device = torch.device('cuda')\n",
        "\n",
        "import re\n",
        "import json\n",
        "import numpy as np\n",
        "from IPython.display import clear_output \n",
        "clear_output()\n",
        "\n",
        "model_name = 'bart_large_xsum'\n",
        "fn_dataset = 'samsum'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1-Ycx_Y4zgw"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/content/drive/MyDrive/Journal/utils')\n",
        "from utils import stripp, replace_apos, replace_phrases, clean_punc, rem_punc, rem_multispace, rem_repeating, rem_fillers, rem_stopwords, clean, check_context, check_req, insert_pronouns, format_summary_, gen_tscs, gen_summaries_\n",
        "from load_dataset_FT import load\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtM_KDq-rOWL"
      },
      "source": [
        "#IMPORTING LIBRARIES AND THE DATASET\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "model_checkpoint = \"facebook/bart-large-xsum\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "train_data, val_data = load(fn_dataset)\n",
        "\n",
        "from datasets import load_metric\n",
        "metric = load_metric(\"rouge\")\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZTa5yGwrOQl"
      },
      "source": [
        "#PREPROCESSING THE DATA\n",
        "\n",
        "max_input_length = 512\n",
        "max_target_length = 128\n",
        "\n",
        "def preprocess_data(examples):\n",
        "    inputs = [doc for doc in examples[\"dialogue\"]]\n",
        "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(examples[\"summary\"], max_length=max_target_length, truncation=True)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "tokenized_train = train_data.map(preprocess_data, batched=True)\n",
        "tokenized_val = val_data.map(preprocess_data, batched=True)\n",
        "del train_data, val_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vk8OALcUrOKL"
      },
      "source": [
        "tokenized_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eALHfsAKr6Aq"
      },
      "source": [
        "### FINE-TUNING THE MODEL ###\n",
        "\n",
        "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtcuXnw0r82C"
      },
      "source": [
        "batch_size = 8\n",
        "save_path = \"/content/drive/MyDrive/Journal/ckpt/{}_{}\".format(model_name, fn_dataset)\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    save_path,\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    gradient_accumulation_steps=2,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=2,\n",
        "    num_train_epochs=4,\n",
        "    predict_with_generate=True,\n",
        "    fp16=True,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATms57XzsAG8"
      },
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYRql8GxIFnf"
      },
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    \n",
        "    # Rouge expects a newline after each sentence\n",
        "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
        "    \n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "    # Extract a few results\n",
        "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
        "    \n",
        "    # Add mean generated length\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    \n",
        "    return {k: round(v, 4) for k, v in result.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rifGIng-t3Vz"
      },
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_val,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYsvpWWUt666"
      },
      "source": [
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqVAxZJCt9Fy"
      },
      "source": [
        "### INFERENCE ###\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=\"{}/checkpoint-3500\".format(save_path))\n",
        "conversation = '''John: Hey, do you have Michael's number?\n",
        "Amy: Lemme check\n",
        "Aakash: Sorry, can't find it.\n",
        "John: Ask Someone\n",
        "Luke: Found it! It was saved in some other contact list\n",
        "Amy: Hey, what happened to the model that we trained?\n",
        "Luke: I think, it would've finished evaluating on the data.\n",
        "John: If it's done evaluating, send me the performances ASAP\n",
        "Amy: Okay, sure.\n",
        "John: And yes, don't forget to upload those on server.\n",
        "Luke: Alright, consider it done\n",
        "John: K then, Bye!\n",
        "Amy: Bye bye                                       \n",
        "'''\n",
        "\n",
        "summary = summarizer(conversation)[0]['summary_text']\n",
        "clear_output()\n",
        "print(summary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StJLtAh5ML2u"
      },
      "source": [
        "eval_data = 'automin'\n",
        "tscs_preprocessed = gen_tscs('automin', tokenizer, 768)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1SyI4DAyXgg"
      },
      "source": [
        "tscs_preprocessed[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOaKWmd3ybRA"
      },
      "source": [
        "out_path = \"/content/drive/MyDrive/Journal/outputs/{}_{}_{}\".format(eval_data, model_name, fn_dataset)\n",
        "s2, filename = gen_summaries_(tscs_preprocessed, summarizer1, out_path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}